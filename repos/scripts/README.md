# Scripts de la Tesis

Herramientas para ejecutar, auditar y documentar las **29 simulaciones ABM+ODE** del proyecto de tesis doctoral *"Irrealismo Operativo de Hiperobjetos"*.

---

## ğŸš€ EjecuciÃ³n de simulaciones

Existen **dos scripts ejecutores** mutuamente excluyentes. Ambos producen `metrics.json` y `report.md` en `{caso}/outputs/`.

| | `cpu_run.sh` | `gpu_run.sh` |
|---|---|---|
| **DÃ³nde corre** | Localmente (Python nativo) | Dentro del contenedor Docker `tesis-gpu` |
| **AceleraciÃ³n** | Solo CPU (NumPy) | GPU via CuPy (sub-batching automÃ¡tico) |
| **Requisitos** | Python 3.10+, dependencias instaladas | Docker + NVIDIA Container Toolkit |
| **Multi-GPU** | N/A | SÃ­ â€” distribuciÃ³n proporcional por VRAM |
| **Velocidad (grid=50)** | ~15s/caso | ~6s/caso |
| **Velocidad (grid=2000)** | ~horas/caso | ~minutos/caso |

---

### `cpu_run.sh` â€” EjecuciÃ³n local en CPU

No requiere Docker ni GPU. Workers paralelos auto-ajustados a los cores disponibles.

```bash
# â”€â”€â”€ BÃ¡sico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh                           # 29 casos, grid por caso, auto workers

# â”€â”€â”€ Caso especÃ­fico (match parcial, case-insensitive) â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh --case clima              # 01_caso_clima
./cpu_run.sh --case deforest           # 16_caso_deforestacion
./cpu_run.sh --case falsacion          # 06, 07, 08 (matchea los 3)

# â”€â”€â”€ Tandas (dividir 29 casos en bloques) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh --parts 3                 # 3 tandas secuenciales
./cpu_run.sh --parts 5 --part 2        # solo la tanda 2 de 5

# â”€â”€â”€ Control de paralelismo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh --workers 4               # mÃ¡ximo 4 procesos simultÃ¡neos

# â”€â”€â”€ Secuencial (1 caso a la vez) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh --step-by-step

# â”€â”€â”€ Previsualizar sin ejecutar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./cpu_run.sh --dry-run
./cpu_run.sh --case falsacion --dry-run
```

**Flags completas:**

| Flag | Default | DescripciÃ³n |
|------|---------|-------------|
| `--parts N` | 1 | Dividir casos en N tandas |
| `--part K` | todas | Ejecutar solo la tanda K de N |
| `--case NOMBRE` | â€” | Filtrar por nombre (match parcial, case-insensitive) |
| `--workers N` | auto | Workers paralelos (auto = `min(nproc, 16)`) |
| `--step-by-step` | off | Secuencial: 1 caso a la vez, output live en terminal |
| `--perm N` | 9999 | Permutaciones para test EDI |
| `--boot N` | 5000 | Bootstrap samples para intervalos de confianza |
| `--refine N` | 50000 | Iteraciones de refinamiento en calibraciÃ³n |
| `--runs N` | 50 | Simulaciones por configuraciÃ³n (C5) |
| `--dry-run` | off | Solo muestra el plan, no ejecuta nada |

**Logs:** `/tmp/cpu_run_logs/{caso}.log`

---

### `gpu_run.sh` â€” EjecuciÃ³n en GPU (Docker)

Ejecuta dentro del contenedor Docker `tesis-gpu`. DistribuciÃ³n multi-GPU dinÃ¡mica con cola de trabajo `flock`. Sub-batching automÃ¡tico en VRAM.

```bash
# â”€â”€â”€ BÃ¡sico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./gpu_run.sh                           # 29 casos, grid por caso, ambas GPUs

# â”€â”€â”€ Caso especÃ­fico â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./gpu_run.sh --case deforest           # 16_caso_deforestacion
./gpu_run.sh --case deforest

# â”€â”€â”€ Forzar una GPU especÃ­fica â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./gpu_run.sh --gpu 0                   # solo RTX 5070 Ti (16 GB)
./gpu_run.sh --gpu 1 --case clima      # solo RTX 2060 (6 GB)

# â”€â”€â”€ Secuencial (1 caso/GPU a la vez) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./gpu_run.sh --step-by-step                        # 2 GPUs: 2 casos simultÃ¡neos (1/GPU)
./gpu_run.sh --step-by-step --gpu 0                # 1 GPU: puramente secuencial

# â”€â”€â”€ Previsualizar sin ejecutar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
./gpu_run.sh --dry-run
./gpu_run.sh --parts 5 --dry-run
```

**Flags completas:**

| Flag | Default | DescripciÃ³n |
|------|---------|-------------|
| `--parts N` | 1 | Dividir en N tandas (1â€“10) |
| `--part K` | todas | Ejecutar solo la tanda K de N |
| `--case NOMBRE` | â€” | Filtrar por nombre (match parcial, case-insensitive) |
| `--gpu N` | auto | Forzar GPU N (0 o 1). Auto = ambas GPUs |
| `--step-by-step` | off | Secuencial: 1 caso/GPU. Con 2 GPUs â†’ 2 simultÃ¡neos |
| `--perm N` | 9999 | Permutaciones para test EDI |
| `--boot N` | 5000 | Bootstrap samples para intervalos de confianza |
| `--refine N` | 50000 | Iteraciones de refinamiento en calibraciÃ³n |
| `--runs N` | 50 | Simulaciones por configuraciÃ³n (C5) |
| `--container C` | tesis-gpu | Nombre del contenedor Docker |
| `--dry-run` | off | Solo muestra el plan, no ejecuta nada |

**Logs:** `docker exec tesis-gpu ls /tmp/gpu_run_logs/`

---

### ğŸ§  Â¿CuÃ¡ndo usar cada modo?

| SituaciÃ³n | Comando recomendado |
|-----------|---------------------|
| Desarrollo rÃ¡pido / debug de un caso | `cpu_run.sh --case NOMBRE` |
| ValidaciÃ³n completa de los 29 casos | `gpu_run.sh` |
| Sensibilidad de grid en un caso | Editar `grid_size` en `validate.py` del caso |
| Secuencial (1 caso por GPU) | `gpu_run.sh --step-by-step --case NOMBRE` |
| Sin GPU disponible | `cpu_run.sh` |
| Prueba rÃ¡pida (params mÃ­nimos) | `--runs 5 --perm 99 --boot 100 --refine 100` |
| Verificar plan sin ejecutar | `--dry-run` (disponible en ambos) |

### âš™ï¸ Arquitectura interna

```
cpu_run.sh                          gpu_run.sh
    â”‚                                   â”‚
    â”œâ”€â”€ flock cola dinÃ¡mica             â”œâ”€â”€ flock cola dinÃ¡mica
    â”œâ”€â”€ N workers (1 por core)          â”œâ”€â”€ N workers (proporcional a VRAM/GPU)
    â”‚                                   â”œâ”€â”€ CUDA_VISIBLE_DEVICES por worker
    â–¼                                   â–¼
  python3 validate.py               docker exec tesis-gpu python3 validate.py
    â”‚                                   â”‚
    â”œâ”€â”€ abm_core.py (NumPy)             â”œâ”€â”€ abm_core_gpu.py (CuPy)
    â”‚                                   â”‚   â””â”€â”€ sub-batching: 25% VRAM libre
    â”œâ”€â”€ ode.py                          â”œâ”€â”€ ode.py
    â”œâ”€â”€ metrics.py â†’ EDI, C1-C5         â”œâ”€â”€ metrics.py â†’ EDI, C1-C5
    â””â”€â”€ outputs/metrics.json            â””â”€â”€ outputs/metrics.json
```

**Sub-batching GPU:** Cada proceso reserva el 25% de la VRAM libre para ejecutar B simulaciones simultÃ¡neas. B se ajusta automÃ¡ticamente segÃºn grid y VRAM disponible. Si OOM con B=1, cae a CPU transparentemente.

**VRAM por proceso (estimada):**

| Grid | RTX 5070 Ti (16 GB) | RTX 2060 (6 GB) |
|------|---------------------|------------------|
| 50 | ~550 MB | ~550 MB |
| 200 | ~650 MB | ~650 MB |
| 500 | ~1450 MB | ~950 MB |
| 2000 | ~2330 MB | ~805 MB |

---

## ğŸ”§ Scripts de utilidad

### AuditorÃ­a y validaciÃ³n

| Script | QuÃ© hace | Uso |
|--------|----------|-----|
| `auditar_simulaciones.py` | AuditorÃ­a documental: estructura, mÃ©tricas, coherencia (solo lectura) | `python3 auditar_simulaciones.py` |
| `auditoria_cientifica_profunda.py` | AuditorÃ­a caso-por-caso: imports, ejecuciÃ³n, resultados | `python3 auditoria_cientifica_profunda.py` |
| `_audit_fresh.py` | AuditorÃ­a rÃ¡pida de todos los `metrics.json` existentes | `python3 _audit_fresh.py` |
| `verificar_consistencia.py` | Verifica sincronizaciÃ³n entre `repos/Simulaciones/` y `TesisDesarrollo/` | `python3 verificar_consistencia.py` |
| `replay_hash.py` | Genera o verifica hashes MD5 de outputs para reproducibilidad | `python3 replay_hash.py --verify` |

### GeneraciÃ³n de documentos

| Script | QuÃ© hace | Uso |
|--------|----------|-----|
| `tesis.py` | CLI principal: scaffold, build, sync, audit, validate | `python3 tesis.py build` |
| `evaluar_simulaciones.py` | Resumen de mÃ©tricas en tablas Markdown | `python3 evaluar_simulaciones.py --write` |
| `actualizar_tablas_002.py` | Actualiza tablas en `02_Modelado_Simulacion.md` desde `metrics.json` | `python3 actualizar_tablas_002.py` |
| `generar_docs_casos.py` | Genera los 5 docs/ estÃ¡ndar para casos 19-29 | `python3 generar_docs_casos.py` |
| `regenerar_readmes.py` | Regenera `README.md` de cada caso desde `metrics.json` | `python3 regenerar_readmes.py` |

### Datos

| Archivo | DescripciÃ³n |
|---------|-------------|
| `tesis_manifest.json` | Manifiesto de secciones de la tesis |
| `replay_baseline.json` | Baseline de hashes MD5 para reproducibilidad |
| `templates/` | Plantillas para scaffolding de nuevos casos |
